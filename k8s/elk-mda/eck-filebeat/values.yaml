configmap:
  enabled: true
  filebeatYaml: |-
                  filebeat.inputs:
                  - type: container
                    paths:
                      - /var/log/containers/
                    processors:
                      - add_kubernetes_metadata:
                          host: ${NODE_NAME}
                          matchers:
                          - logs_path:
                              logs_path: "/var/log/containers/"
                  
                  #setup.dashboards.enabled: true
                  #setup.kibana.host: elastic-eck-kibana-kb-http:5601
                  #setup.kibana.protocol: https
                  #setup.kibana.ssl.enabled: true
                  #setup.kibana.ssl.verification_mode: none
                  #setup.kibana.username: elastic
                  #setup.kibana.password: S5p3XP1HXL1dURK6L58Z58y6

                  # To enable hints based autodiscover, remove `filebeat.inputs` configuration and uncomment this:
                  filebeat.autodiscover:
                    providers:
                      - type: kubernetes
                        node: ${NODE_NAME}
                        hints.enabled: false
                        hints.default_config:
                          type: container
                          paths:
                            - /var/log/containers/*${data.kubernetes.container.id}.log
                        templates:
                        - condition.equals.kubernetes.namespace: grafana
                          config:
                          - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                            type: container          
                        - condition.equals.kubernetes.namespace: victoriametrics-workload
                          config:
                          - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                            type: container              
                        - condition.equals.kubernetes.namespace: victoriametrics
                          config:
                          - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                            type: container
                        - condition.equals.kubernetes.namespace: kafka
                          config:
                          - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                            type: container
                        - condition.equals.kubernetes.namespace: alerta
                          config:
                          - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                            type: container
                        - condition.equals.kubernetes.namespace: cmak
                          config:
                          - paths: ["/var/log/containers/*${data.kubernetes.container.id}.log"]
                            type: container
                            
                  processors:
                    - add_cloud_metadata:
                    - add_host_metadata:

                  cloud.id: ${ELASTIC_CLOUD_ID}
                  cloud.auth: ${ELASTIC_CLOUD_AUTH}

                  output.kafka:
                    enabled: true
                    hosts: ["kafka.kafka.svc.cluster.local:9092"]
                    topic: "logs"
                    codec.json:
                      pretty: false
                    partition.round_robin:
                    reachable_only: false
                    required_acks: 1
                    max_message_bytes: 1000000
                    close_inactive: 50m

daemonset:
#For the Daemonset the Configmap has to be enabled also
  enabled: true
  spec:
    selector:
      matchLabels:
        k8s-app: elastic-filebeat
    template:
      metadata:
        labels:
          k8s-app: elastic-filebeat
      spec:
        serviceAccountName: filebeat
        terminationGracePeriodSeconds: 30
        hostNetwork: true
        dnsPolicy: ClusterFirstWithHostNet
        containers:
        - name: filebeat
          image: docker.elastic.co/beats/filebeat:8.4.3
          args: [
            "-c", "/etc/filebeat.yml",
            "-e",
          ]
          env:
          - name: KAFKA_HOST
            value: kafka-cluster-kafka-bootstrap-external-elastic:9092
          - name: KAFKA_TOPIC
            value: logs
          - name: ELASTICSEARCH_HOST
            value: elastic-eck-elasticsearch-es-http
          - name: ELASTICSEARCH_PORT
            value: "9200"
          - name: ELASTICSEARCH_USERNAME
            value: elastic
#          - name: ELASTICSEARCH_PASSWORD
#            valueFrom:
#              secretKeyRef:
#                name: elastic-eck-elasticsearch-es-elastic-user
#                key: elastic
          - name: ELASTIC_CLOUD_ID
            value:
          - name: ELASTIC_CLOUD_AUTH
            value:
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          securityContext:
            runAsUser: 0
            # If using Red Hat OpenShift uncomment this:
            #privileged: true
          resources:
            limits:
              memory: 400Mi
            requests:
              cpu: 100m
              memory: 200Mi
          volumeMounts:
          - name: config
            mountPath: /etc/filebeat.yml
            readOnly: true
            subPath: filebeat.yml
          - name: data
            mountPath: /usr/share/filebeat/data
          - name: varlibdockercontainers
            mountPath: /var/lib/docker/containers
            readOnly: true
          - name: varlog
            mountPath: /var/log
            readOnly: true
        volumes:
        - name: config
          configMap:
            defaultMode: 0640
            name: filebeat-config
        - name: varlibdockercontainers
          hostPath:
            path: /var/lib/docker/containers
        - name: varlog
          hostPath:
            path: /var/log
        # data folder stores a registry of read status for all files, so we don't send everything again on a Filebeat pod restart
        - name: data
          hostPath:
            # When filebeat runs as non-root user, this directory needs to be writable by group (g+w).
            path: /var/lib/filebeat-data
            type: DirectoryOrCreateufferOverflowError error="buffer space has too many data" location="/fluentd/vendor/bundle/ruby/